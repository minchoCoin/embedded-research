{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YMh4BD1BfsYu"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import pathlib\n",
        "from scipy.io import wavfile\n",
        "from collections import defaultdict, Counter\n",
        "from scipy import signal\n",
        "import numpy as np\n",
        "import librosa\n",
        "import sklearn\n",
        "import random\n",
        "from unicodedata import normalize\n",
        "from tensorflow.keras import layers,models\n",
        "import librosa.display\n",
        "import tensorflow as tf\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET_PATH = 'data/mini_speech_commands'\n",
        "\n",
        "data_dir = pathlib.Path(DATASET_PATH)\n",
        "if not data_dir.exists():\n",
        "  tf.keras.utils.get_file(\n",
        "      'mini_speech_commands.zip',\n",
        "      origin=\"http://storage.googleapis.com/download.tensorflow.org/data/mini_speech_commands.zip\",\n",
        "      extract=True,\n",
        "      cache_dir='.', cache_subdir='data')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LIgSNkIAf-0X",
        "outputId": "212c8a95-3918-4fa9-d46c-38aea26bfcd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from http://storage.googleapis.com/download.tensorflow.org/data/mini_speech_commands.zip\n",
            "\u001b[1m182082353/182082353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "commands = np.array(tf.io.gfile.listdir(str(data_dir)))\n",
        "commands = commands[commands != 'README.md']\n",
        "print('Commands:', commands)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wTmYvWDBgBO5",
        "outputId": "826e3dd1-28a8-471a-fa7e-32b07e1a9844"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Commands: ['left' 'go' 'yes' 'no' 'stop' 'up' 'right' 'down']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = []\n",
        "y = []"
      ],
      "metadata": {
        "id": "DtA24rexgCRe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pad1d = lambda a, i: a[0: i] if a.shape[0] > i else np.hstack((a, np.zeros(i-a.shape[0])))\n",
        "pad2d = lambda a, i: a[:, 0:i] if a.shape[1] > i else np.hstack((a, np.zeros((a.shape[0], i-a.shape[1]))))"
      ],
      "metadata": {
        "id": "QaJDk6CtgDXp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train data를 넣는다.\n",
        "target = ['up', 'down', 'left', 'right','go','stop','yes','no']\n",
        "for item in os.listdir(DATASET_PATH):\n",
        "    sub_folder = os.path.join(DATASET_PATH,item)\n",
        "    if os.path.isdir(sub_folder):\n",
        "      print(sub_folder)\n",
        "      for filename in os.listdir(sub_folder):\n",
        "        filename = normalize('NFC', filename)\n",
        "        try:\n",
        "    # wav 포맷 데이터만 사용\n",
        "          if '.wav' not in filename in filename:\n",
        "              continue\n",
        "\n",
        "          wav, sr = librosa.load(os.path.join(sub_folder,filename), sr=16000)\n",
        "\n",
        "          stft = np.abs(librosa.stft(y=wav, n_fft=256, hop_length=128))\n",
        "#         mfcc = sklearn.preprocessing.scale(mfcc, axis=1)\n",
        "\n",
        "          padded_stft = pad2d(stft, 120)\n",
        "\n",
        "          x.append(padded_stft)\n",
        "          y.append(target.index(item))\n",
        "        except Exception as e:\n",
        "          print(filename,e)\n",
        "          raise"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_oNbDrabgL-V",
        "outputId": "28842851-8f15-4c6e-ec80-a694c22da0db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data/mini_speech_commands/left\n",
            "data/mini_speech_commands/go\n",
            "data/mini_speech_commands/yes\n",
            "data/mini_speech_commands/no\n",
            "data/mini_speech_commands/stop\n",
            "data/mini_speech_commands/up\n",
            "data/mini_speech_commands/right\n",
            "data/mini_speech_commands/down\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=np.array(x)\n",
        "y=np.array(y)"
      ],
      "metadata": {
        "id": "uERU3K4ygNvw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42bA4Kxem2nI",
        "outputId": "739931fa-4bf5-41a8-c213-588f7d9c919e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8000, 129, 120)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DeMkEeJRr2c0",
        "outputId": "363d81dc-3106-4d80-aa7b-2a55119c0d97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8000,)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "interpreter = tf.lite.Interpreter(model_path='./model.tflite')\n",
        "interpreter.allocate_tensors()"
      ],
      "metadata": {
        "id": "AsHwsMt1g8p3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()"
      ],
      "metadata": {
        "id": "3ozYEObShBjZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_scale, input_zero_point = input_details[0]['quantization']\n",
        "output_scale, output_zero_point = output_details[0]['quantization']\n",
        "\n",
        "input_scale,input_zero_point,output_scale,output_zero_point"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qdUJ1xuMilrj",
        "outputId": "2ab079fa-ef28-413b-fb8e-8b71933d58e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.1303439885377884, -128, 0.00390625, -128)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#quantization\n",
        "x=x/input_scale + input_zero_point\n",
        "x=x.astype(np.int8)"
      ],
      "metadata": {
        "id": "utq6h2GjiwAi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = x.shape[0]"
      ],
      "metadata": {
        "id": "sxZ0ghhli4x2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = []\n",
        "for i in range(batch_size):\n",
        "  interpreter.set_tensor(input_details[0]['index'],x[i:i+1])\n",
        "  interpreter.invoke()\n",
        "  quantized_output = interpreter.get_tensor(output_details[0]['index'])\n",
        "  output.append(np.argmax((quantized_output.astype(np.float32)-output_zero_point)*output_scale))\n"
      ],
      "metadata": {
        "id": "keaP77Aki9uR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = np.array(output)\n"
      ],
      "metadata": {
        "id": "3dRYQrkykit9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.sum(output == y) / len(output)"
      ],
      "metadata": {
        "id": "NKhZKybSlHn1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd53c566-9e82-49fc-cb0e-fd7cc91cb366"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.72025"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    }
  ]
}